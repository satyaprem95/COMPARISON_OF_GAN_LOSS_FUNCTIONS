{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from scipy.linalg import sqrtm\n",
    "import medmnist\n",
    "from medmnist import INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Ensure reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Verify GPU availability\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Set GPU memory growth to prevent TensorFlow from allocating all GPU memory\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU memory growth enabled.\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error setting memory growth:\", e)\n",
    "\n",
    "# --- Dataset Loading and Preprocessing ---\n",
    "def load_retinamnist():\n",
    "    \"\"\"Load and preprocess the RetinaMNIST dataset from MedMNIST.\"\"\"\n",
    "    info = INFO['retinamnist']\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "    train_dataset = DataClass(split='train', download=True)\n",
    "    x_train = train_dataset.imgs  # Shape: (N, 28, 28)\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32')\n",
    "    x_train = (x_train - 127.5) / 127.5  # Normalize to [-1, 1]\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_retinamnist()\n",
    "batch_size = 64\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(10000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Definitions ---\n",
    "def build_generator(noise_dim=100):\n",
    "    \"\"\"Build the generator model.\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(7*7*128, input_dim=noise_dim),\n",
    "        layers.Reshape((7, 7, 128)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2DTranspose(64, 4, strides=2, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2DTranspose(32, 4, strides=2, padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2D(1, 3, padding='same', activation='tanh')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_discriminator_ls():\n",
    "    \"\"\"Build the discriminator for LS-GAN.\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(32, 3, strides=2, padding='same', input_shape=(28, 28, 1)),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(64, 3, strides=2, padding='same'),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_critic_wgan():\n",
    "    \"\"\"Build the critic for WGAN.\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(32, 3, strides=2, padding='same', input_shape=(28, 28, 1)),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2D(64, 3, strides=2, padding='same'),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# WGAN-GP uses the same critic architecture\n",
    "build_critic_wgan_gp = build_critic_wgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loss Functions ---\n",
    "def ls_discriminator_loss(real_output, fake_output):\n",
    "    \"\"\"Least squares loss for LS-GAN discriminator.\"\"\"\n",
    "    real_loss = tf.reduce_mean(tf.square(real_output - 1))\n",
    "    fake_loss = tf.reduce_mean(tf.square(fake_output))\n",
    "    return 0.5 * (real_loss + fake_loss)\n",
    "\n",
    "def ls_generator_loss(fake_output):\n",
    "    \"\"\"Least squares loss for LS-GAN generator.\"\"\"\n",
    "    return tf.reduce_mean(tf.square(fake_output - 1))\n",
    "\n",
    "def wgan_critic_loss(real_output, fake_output):\n",
    "    \"\"\"Wasserstein loss for WGAN critic.\"\"\"\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "def wgan_generator_loss(fake_output):\n",
    "    \"\"\"Wasserstein loss for WGAN generator.\"\"\"\n",
    "    return -tf.reduce_mean(fake_output)\n",
    "\n",
    "def gradient_penalty(critic, real_images, fake_images, batch_size, lambda_gp=10):\n",
    "    \"\"\"Compute gradient penalty for WGAN-GP.\"\"\"\n",
    "    epsilon = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "    interpolated = epsilon * real_images + (1 - epsilon) * fake_images\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        critic_interpolated = critic(interpolated, training=True)\n",
    "    grads = gp_tape.gradient(critic_interpolated, interpolated)\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return lambda_gp * gp\n",
    "\n",
    "def wgan_gp_critic_loss(critic, real_images, fake_images, batch_size, lambda_gp=10):\n",
    "    \"\"\"Wasserstein loss with gradient penalty for WGAN-GP critic.\"\"\"\n",
    "    real_output = critic(real_images, training=True)\n",
    "    fake_output = critic(fake_images, training=True)\n",
    "    c_loss = tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "    gp = gradient_penalty(critic, real_images, fake_images, batch_size)\n",
    "    return c_loss + gp\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Convert a Matplotlib figure to a TensorFlow image tensor for TensorBoard.\"\"\"\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "# Load InceptionV3 for evaluation\n",
    "inception_model = keras.applications.InceptionV3(include_top=True, input_shape=(299, 299, 3))\n",
    "feature_extractor = keras.Model(inputs=inception_model.input, outputs=inception_model.get_layer('avg_pool').output)\n",
    "\n",
    "def compute_is(generator, noise_dim, num_samples=1000):\n",
    "    \"\"\"Compute Inception Score.\"\"\"\n",
    "    noise = tf.random.normal([num_samples, noise_dim])\n",
    "    generated_images = generator(noise, training=False)\n",
    "    generated_images = (generated_images + 1) / 2  # Rescale to [0, 1]\n",
    "    generated_images = tf.image.resize(generated_images, [299, 299])\n",
    "    generated_images = tf.repeat(generated_images, 3, axis=-1)  # Grayscale to RGB\n",
    "    preds = inception_model.predict(generated_images, batch_size=32)\n",
    "    preds = tf.nn.softmax(preds, axis=1)\n",
    "    kl_div = tf.reduce_sum(preds * (tf.math.log(preds + 1e-10) - tf.math.log(tf.reduce_mean(preds, axis=0) + 1e-10)), axis=1)\n",
    "    is_score = tf.exp(tf.reduce_mean(kl_div))\n",
    "    return is_score.numpy()\n",
    "\n",
    "def compute_fid(generator, real_images, noise_dim, num_samples=1000):\n",
    "    \"\"\"Compute Fr√©chet Inception Distance.\"\"\"\n",
    "    noise = tf.random.normal([num_samples, noise_dim])\n",
    "    generated_images = generator(noise, training=False)\n",
    "    generated_images = (generated_images + 1) / 2\n",
    "    generated_images = tf.image.resize(generated_images, [299, 299])\n",
    "    generated_images = tf.repeat(generated_images, 3, axis=-1)\n",
    "    \n",
    "    real_images = real_images[:num_samples]\n",
    "    real_images = (real_images + 1) / 2\n",
    "    real_images = tf.image.resize(real_images, [299, 299])\n",
    "    real_images = tf.repeat(real_images, 3, axis=-1)\n",
    "    \n",
    "    real_features = feature_extractor.predict(real_images, batch_size=32)\n",
    "    generated_features = feature_extractor.predict(generated_images, batch_size=32)\n",
    "    \n",
    "    mu_real, sigma_real = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n",
    "    mu_gen, sigma_gen = np.mean(generated_features, axis=0), np.cov(generated_features, rowvar=False)\n",
    "    \n",
    "    diff = mu_real - mu_gen\n",
    "    covmean = sqrtm(sigma_real.dot(sigma_gen))\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid = np.sum(diff**2) + np.trace(sigma_real + sigma_gen - 2*covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Functions ---\n",
    "def train_ls_gan(generator, discriminator, dataset, epochs=50, batch_size=64, noise_dim=100):\n",
    "    \"\"\"Train LS-GAN.\"\"\"\n",
    "    d_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    g_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    log_dir = 'logs/ls_gan'\n",
    "    summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for real_images in dataset:\n",
    "            batch_size_current = real_images.shape[0]\n",
    "            noise = tf.random.normal([batch_size_current, noise_dim])\n",
    "            with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
    "                generated_images = generator(noise, training=True)\n",
    "                real_output = discriminator(real_images, training=True)\n",
    "                fake_output = discriminator(generated_images, training=True)\n",
    "                d_loss = ls_discriminator_loss(real_output, fake_output)\n",
    "                g_loss = ls_generator_loss(fake_output)\n",
    "            d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "            g_grads = g_tape.gradient(g_loss, generator.trainable_variables)\n",
    "            d_optimizer.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
    "            g_optimizer.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
    "        \n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('d_loss', d_loss, step=epoch)\n",
    "            tf.summary.scalar('g_loss', g_loss, step=epoch)\n",
    "            summary_writer.flush()\n",
    "            if epoch % 10 == 0:\n",
    "                generated_images = generator(tf.random.normal([16, noise_dim]), training=False)\n",
    "                fig, axes = plt.subplots(4, 4, figsize=(4, 4))\n",
    "                for i, ax in enumerate(axes.flat):\n",
    "                    ax.imshow(generated_images[i, :, :, 0] * 0.5 + 0.5, cmap='gray')\n",
    "                    ax.axis('off')\n",
    "                tf.summary.image('generated_images', plot_to_image(fig), step=epoch)\n",
    "        print(f'LS-GAN Epoch {epoch+1}/{epochs}, D_loss: {d_loss:.4f}, G_loss: {g_loss:.4f}')\n",
    "\n",
    "def train_wgan(generator, critic, dataset, epochs=50, batch_size=64, noise_dim=100, n_critic=5, clip_value=0.01):\n",
    "    \"\"\"Train a Wasserstein GAN.\"\"\"\n",
    "    g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n",
    "    c_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n",
    "    log_dir = 'logs/wgan'\n",
    "    summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train the critic\n",
    "        for _ in range(n_critic):\n",
    "            real_images = next(iter(dataset))\n",
    "            batch_size_current = real_images.shape[0]\n",
    "            noise = tf.random.normal([batch_size_current, noise_dim])\n",
    "            with tf.GradientTape() as c_tape:\n",
    "                generated_images = generator(noise, training=True)\n",
    "                real_output = critic(real_images, training=True)\n",
    "                fake_output = critic(generated_images, training=True)\n",
    "                c_loss = tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)  # WGAN critic loss\n",
    "            c_grads = c_tape.gradient(c_loss, critic.trainable_variables)\n",
    "            c_optimizer.apply_gradients(zip(c_grads, critic.trainable_variables))\n",
    "            # Clip critic weights\n",
    "            for var in critic.trainable_variables:\n",
    "                var.assign(tf.clip_by_value(var, -clip_value, clip_value))\n",
    "\n",
    "        # Train the generator\n",
    "        noise = tf.random.normal([batch_size, noise_dim])\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            generated_images = generator(noise, training=True)\n",
    "            fake_output = critic(generated_images, training=True)\n",
    "            g_loss = -tf.reduce_mean(fake_output)  # WGAN generator loss\n",
    "        g_grads = g_tape.gradient(g_loss, generator.trainable_variables)\n",
    "        g_optimizer.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
    "\n",
    "        # Log losses and print progress\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('c_loss', c_loss, step=epoch)\n",
    "            tf.summary.scalar('g_loss', g_loss, step=epoch)\n",
    "            summary_writer.flush()\n",
    "        print(f'WGAN Epoch {epoch+1}/{epochs}, C_loss: {c_loss:.4f}, G_loss: {g_loss:.4f}')\n",
    "        \n",
    "def train_wgan_gp(generator, critic, dataset, epochs=50, batch_size=64, noise_dim=100, n_critic=5, lambda_gp=10):\n",
    "    \"\"\"Train WGAN-GP.\"\"\"\n",
    "    g_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n",
    "    c_optimizer = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n",
    "    log_dir = 'logs/wgan_gp'\n",
    "    summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(n_critic):\n",
    "            real_images = next(iter(dataset))\n",
    "            batch_size_current = real_images.shape[0]\n",
    "            noise = tf.random.normal([batch_size_current, noise_dim])\n",
    "            with tf.GradientTape() as c_tape:\n",
    "                generated_images = generator(noise, training=True)\n",
    "                c_loss = wgan_gp_critic_loss(critic, real_images, generated_images, batch_size_current, lambda_gp)\n",
    "            c_grads = c_tape.gradient(c_loss, critic.trainable_variables)\n",
    "            c_optimizer.apply_gradients(zip(c_grads, critic.trainable_variables))\n",
    "        \n",
    "        noise = tf.random.normal([batch_size, noise_dim])\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            generated_images = generator(noise, training=True)\n",
    "            fake_output = critic(generated_images, training=True)\n",
    "            g_loss = wgan_generator_loss(fake_output)\n",
    "        g_grads = g_tape.gradient(g_loss, generator.trainable_variables)\n",
    "        g_optimizer.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
    "        \n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('c_loss', c_loss, step=epoch)\n",
    "            tf.summary.scalar('g_loss', g_loss, step=epoch)\n",
    "            summary_writer.flush()\n",
    "            if epoch % 10 == 0:\n",
    "                generated_images = generator(tf.random.normal([16, noise_dim]), training=False)\n",
    "                fig, axes = plt.subplots(4, 4, figsize=(4, 4))\n",
    "                for i, ax in enumerate(axes.flat):\n",
    "                    ax.imshow(generated_images[i, :, :, 0] * 0.5 + 0.5, cmap='gray')\n",
    "                    ax.axis('off')\n",
    "                tf.summary.image('generated_images', plot_to_image(fig), step=epoch)\n",
    "        print(f'WGAN-GP Epoch {epoch+1}/{epochs}, C_loss: {c_loss:.4f}, G_loss: {g_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution ---\n",
    "def main():\n",
    "    noise_dim = 100\n",
    "    epochs = 50\n",
    "\n",
    "    # LS-GAN\n",
    "    print(\"Training LS-GAN...\")\n",
    "    generator_ls = build_generator(noise_dim)\n",
    "    discriminator_ls = build_discriminator_ls()\n",
    "    train_ls_gan(generator_ls, discriminator_ls, dataset, epochs, batch_size, noise_dim)\n",
    "    is_score_ls = compute_is(generator_ls, noise_dim)\n",
    "    fid_score_ls = compute_fid(generator_ls, x_train, noise_dim)\n",
    "    print(f'LS-GAN Evaluation - IS: {is_score_ls:.4f}, FID: {fid_score_ls:.4f}\\n')\n",
    "\n",
    "    # WGAN\n",
    "    print(\"Training WGAN...\")\n",
    "    generator_wgan = build_generator(noise_dim)\n",
    "    critic_wgan = build_critic_wgan()\n",
    "    train_wgan(generator_wgan, critic_wgan, dataset, epochs, batch_size, noise_dim)\n",
    "    is_score_wgan = compute_is(generator_wgan, noise_dim)\n",
    "    fid_score_wgan = compute_fid(generator_wgan, x_train, noise_dim)\n",
    "    print(f'WGAN Evaluation - IS: {is_score_wgan:.4f}, FID: {fid_score_wgan:.4f}\\n')\n",
    "\n",
    "    # WGAN-GP\n",
    "    print(\"Training WGAN-GP...\")\n",
    "    generator_wgan_gp = build_generator(noise_dim)\n",
    "    critic_wgan_gp = build_critic_wgan_gp()\n",
    "    train_wgan_gp(generator_wgan_gp, critic_wgan_gp, dataset, epochs, batch_size, noise_dim)\n",
    "    is_score_wgan_gp = compute_is(generator_wgan_gp, noise_dim)\n",
    "    fid_score_wgan_gp = compute_fid(generator_wgan_gp, x_train, noise_dim)\n",
    "    print(f'WGAN-GP Evaluation - IS: {is_score_wgan_gp:.4f}, FID: {fid_score_wgan_gp:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LS-GAN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rohan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\rohan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS-GAN Epoch 1/50, D_loss: 0.2582, G_loss: 0.2350\n",
      "LS-GAN Epoch 2/50, D_loss: 0.2373, G_loss: 0.2742\n",
      "LS-GAN Epoch 3/50, D_loss: 0.2243, G_loss: 0.2791\n",
      "LS-GAN Epoch 4/50, D_loss: 0.2132, G_loss: 0.3225\n",
      "LS-GAN Epoch 5/50, D_loss: 0.2194, G_loss: 0.2662\n",
      "LS-GAN Epoch 6/50, D_loss: 0.2225, G_loss: 0.3224\n",
      "LS-GAN Epoch 7/50, D_loss: 0.2158, G_loss: 0.2952\n",
      "LS-GAN Epoch 8/50, D_loss: 0.2237, G_loss: 0.2924\n",
      "LS-GAN Epoch 9/50, D_loss: 0.2285, G_loss: 0.2968\n",
      "LS-GAN Epoch 10/50, D_loss: 0.2193, G_loss: 0.2974\n",
      "LS-GAN Epoch 11/50, D_loss: 0.2267, G_loss: 0.2769\n",
      "LS-GAN Epoch 12/50, D_loss: 0.2171, G_loss: 0.2739\n",
      "LS-GAN Epoch 13/50, D_loss: 0.2264, G_loss: 0.2845\n",
      "LS-GAN Epoch 14/50, D_loss: 0.2222, G_loss: 0.2985\n",
      "LS-GAN Epoch 15/50, D_loss: 0.2351, G_loss: 0.2830\n",
      "LS-GAN Epoch 16/50, D_loss: 0.2193, G_loss: 0.2753\n",
      "LS-GAN Epoch 17/50, D_loss: 0.2394, G_loss: 0.2894\n",
      "LS-GAN Epoch 18/50, D_loss: 0.2256, G_loss: 0.2860\n",
      "LS-GAN Epoch 19/50, D_loss: 0.2316, G_loss: 0.2704\n",
      "LS-GAN Epoch 20/50, D_loss: 0.2331, G_loss: 0.2728\n",
      "LS-GAN Epoch 21/50, D_loss: 0.2341, G_loss: 0.2774\n",
      "LS-GAN Epoch 22/50, D_loss: 0.2346, G_loss: 0.2681\n",
      "LS-GAN Epoch 23/50, D_loss: 0.2309, G_loss: 0.2664\n",
      "LS-GAN Epoch 24/50, D_loss: 0.2384, G_loss: 0.2815\n",
      "LS-GAN Epoch 25/50, D_loss: 0.2215, G_loss: 0.3048\n",
      "LS-GAN Epoch 26/50, D_loss: 0.2600, G_loss: 0.2589\n",
      "LS-GAN Epoch 27/50, D_loss: 0.2367, G_loss: 0.2926\n",
      "LS-GAN Epoch 28/50, D_loss: 0.2505, G_loss: 0.2619\n",
      "LS-GAN Epoch 29/50, D_loss: 0.2399, G_loss: 0.2917\n",
      "LS-GAN Epoch 30/50, D_loss: 0.2369, G_loss: 0.2754\n",
      "LS-GAN Epoch 31/50, D_loss: 0.2554, G_loss: 0.2592\n",
      "LS-GAN Epoch 32/50, D_loss: 0.2388, G_loss: 0.2516\n",
      "LS-GAN Epoch 33/50, D_loss: 0.2365, G_loss: 0.2633\n",
      "LS-GAN Epoch 34/50, D_loss: 0.2565, G_loss: 0.2783\n",
      "LS-GAN Epoch 35/50, D_loss: 0.2398, G_loss: 0.2789\n",
      "LS-GAN Epoch 36/50, D_loss: 0.2446, G_loss: 0.2388\n",
      "LS-GAN Epoch 37/50, D_loss: 0.2544, G_loss: 0.2361\n",
      "LS-GAN Epoch 38/50, D_loss: 0.2516, G_loss: 0.2549\n",
      "LS-GAN Epoch 39/50, D_loss: 0.2373, G_loss: 0.2563\n",
      "LS-GAN Epoch 40/50, D_loss: 0.2573, G_loss: 0.2333\n",
      "LS-GAN Epoch 41/50, D_loss: 0.2424, G_loss: 0.2552\n",
      "LS-GAN Epoch 42/50, D_loss: 0.2276, G_loss: 0.3041\n",
      "LS-GAN Epoch 43/50, D_loss: 0.2435, G_loss: 0.2824\n",
      "LS-GAN Epoch 44/50, D_loss: 0.2366, G_loss: 0.2522\n",
      "LS-GAN Epoch 45/50, D_loss: 0.2364, G_loss: 0.2601\n",
      "LS-GAN Epoch 46/50, D_loss: 0.2363, G_loss: 0.2787\n",
      "LS-GAN Epoch 47/50, D_loss: 0.2495, G_loss: 0.2678\n",
      "LS-GAN Epoch 48/50, D_loss: 0.2337, G_loss: 0.2660\n",
      "LS-GAN Epoch 49/50, D_loss: 0.2489, G_loss: 0.2468\n",
      "LS-GAN Epoch 50/50, D_loss: 0.2453, G_loss: 0.2538\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 862ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 890ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 789ms/step\n",
      "LS-GAN Evaluation - IS: 1.0001, FID: 25.7550\n",
      "\n",
      "Training WGAN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rohan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\rohan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WGAN Epoch 1/50, C_loss: -0.0031, G_loss: 0.0017\n",
      "WGAN Epoch 2/50, C_loss: -0.0045, G_loss: 0.0015\n",
      "WGAN Epoch 3/50, C_loss: -0.0052, G_loss: 0.0020\n",
      "WGAN Epoch 4/50, C_loss: -0.0080, G_loss: 0.0033\n",
      "WGAN Epoch 5/50, C_loss: -0.0116, G_loss: 0.0057\n",
      "WGAN Epoch 6/50, C_loss: -0.0155, G_loss: 0.0103\n",
      "WGAN Epoch 7/50, C_loss: -0.0214, G_loss: 0.0166\n",
      "WGAN Epoch 8/50, C_loss: -0.0326, G_loss: 0.0248\n",
      "WGAN Epoch 9/50, C_loss: -0.0421, G_loss: 0.0304\n",
      "WGAN Epoch 10/50, C_loss: -0.0538, G_loss: 0.0403\n",
      "WGAN Epoch 11/50, C_loss: -0.0647, G_loss: 0.0493\n",
      "WGAN Epoch 12/50, C_loss: -0.0775, G_loss: 0.0702\n",
      "WGAN Epoch 13/50, C_loss: -0.0924, G_loss: 0.1105\n",
      "WGAN Epoch 14/50, C_loss: -0.1222, G_loss: 0.1186\n",
      "WGAN Epoch 15/50, C_loss: -0.1368, G_loss: 0.1543\n",
      "WGAN Epoch 16/50, C_loss: -0.1529, G_loss: 0.1845\n",
      "WGAN Epoch 17/50, C_loss: -0.1849, G_loss: 0.1829\n",
      "WGAN Epoch 18/50, C_loss: -0.2103, G_loss: 0.1850\n",
      "WGAN Epoch 19/50, C_loss: -0.2495, G_loss: 0.2112\n",
      "WGAN Epoch 20/50, C_loss: -0.2948, G_loss: 0.2568\n",
      "WGAN Epoch 21/50, C_loss: -0.3166, G_loss: 0.3306\n",
      "WGAN Epoch 22/50, C_loss: -0.3258, G_loss: 0.3809\n",
      "WGAN Epoch 23/50, C_loss: -0.2526, G_loss: 0.3655\n",
      "WGAN Epoch 24/50, C_loss: -0.1268, G_loss: 0.2211\n",
      "WGAN Epoch 25/50, C_loss: -0.1190, G_loss: 0.1259\n",
      "WGAN Epoch 26/50, C_loss: -0.1856, G_loss: 0.0852\n",
      "WGAN Epoch 27/50, C_loss: -0.2181, G_loss: 0.0645\n",
      "WGAN Epoch 28/50, C_loss: -0.2207, G_loss: 0.0556\n",
      "WGAN Epoch 29/50, C_loss: -0.1426, G_loss: 0.0708\n",
      "WGAN Epoch 30/50, C_loss: -0.1063, G_loss: 0.1127\n",
      "WGAN Epoch 31/50, C_loss: -0.1144, G_loss: 0.2334\n",
      "WGAN Epoch 32/50, C_loss: -0.1292, G_loss: 0.3374\n",
      "WGAN Epoch 33/50, C_loss: -0.1538, G_loss: 0.4120\n",
      "WGAN Epoch 34/50, C_loss: -0.1918, G_loss: 0.4726\n",
      "WGAN Epoch 35/50, C_loss: -0.2402, G_loss: 0.5023\n",
      "WGAN Epoch 36/50, C_loss: -0.2905, G_loss: 0.5328\n",
      "WGAN Epoch 37/50, C_loss: -0.3235, G_loss: 0.5463\n",
      "WGAN Epoch 38/50, C_loss: -0.3238, G_loss: 0.5033\n",
      "WGAN Epoch 39/50, C_loss: -0.3385, G_loss: 0.4489\n",
      "WGAN Epoch 40/50, C_loss: -0.3280, G_loss: 0.3563\n",
      "WGAN Epoch 41/50, C_loss: -0.2778, G_loss: 0.2416\n",
      "WGAN Epoch 42/50, C_loss: -0.2516, G_loss: 0.1689\n",
      "WGAN Epoch 43/50, C_loss: -0.2598, G_loss: 0.1752\n",
      "WGAN Epoch 44/50, C_loss: -0.2822, G_loss: 0.1951\n",
      "WGAN Epoch 45/50, C_loss: -0.3336, G_loss: 0.2109\n",
      "WGAN Epoch 46/50, C_loss: -0.3099, G_loss: 0.1986\n",
      "WGAN Epoch 47/50, C_loss: -0.2494, G_loss: 0.1882\n",
      "WGAN Epoch 48/50, C_loss: -0.2523, G_loss: 0.2087\n",
      "WGAN Epoch 49/50, C_loss: -0.2780, G_loss: 0.2854\n",
      "WGAN Epoch 50/50, C_loss: -0.2771, G_loss: 0.3393\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 821ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 829ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 823ms/step\n",
      "WGAN Evaluation - IS: 1.0000, FID: 263.3366\n",
      "\n",
      "Training WGAN-GP...\n",
      "WGAN-GP Epoch 1/50, C_loss: 7.0572, G_loss: 0.0248\n",
      "WGAN-GP Epoch 2/50, C_loss: 6.6312, G_loss: -0.0525\n",
      "WGAN-GP Epoch 3/50, C_loss: 6.2336, G_loss: -0.1745\n",
      "WGAN-GP Epoch 4/50, C_loss: 5.8408, G_loss: -0.3028\n",
      "WGAN-GP Epoch 5/50, C_loss: 5.4158, G_loss: -0.4055\n",
      "WGAN-GP Epoch 6/50, C_loss: 4.9001, G_loss: -0.4890\n",
      "WGAN-GP Epoch 7/50, C_loss: 4.3131, G_loss: -0.6880\n",
      "WGAN-GP Epoch 8/50, C_loss: 3.9398, G_loss: -0.9568\n",
      "WGAN-GP Epoch 9/50, C_loss: 3.4794, G_loss: -1.1956\n",
      "WGAN-GP Epoch 10/50, C_loss: 3.1323, G_loss: -1.3145\n",
      "WGAN-GP Epoch 11/50, C_loss: 2.7009, G_loss: -1.4084\n",
      "WGAN-GP Epoch 12/50, C_loss: 2.3064, G_loss: -1.4657\n",
      "WGAN-GP Epoch 13/50, C_loss: 2.1288, G_loss: -1.6236\n",
      "WGAN-GP Epoch 14/50, C_loss: 2.0253, G_loss: -1.9615\n",
      "WGAN-GP Epoch 15/50, C_loss: 2.2061, G_loss: -2.1773\n",
      "WGAN-GP Epoch 16/50, C_loss: 2.2152, G_loss: -2.3412\n",
      "WGAN-GP Epoch 17/50, C_loss: 1.9409, G_loss: -2.7709\n",
      "WGAN-GP Epoch 18/50, C_loss: 1.9412, G_loss: -2.9570\n",
      "WGAN-GP Epoch 19/50, C_loss: 2.1743, G_loss: -2.9025\n",
      "WGAN-GP Epoch 20/50, C_loss: 2.0595, G_loss: -2.9680\n",
      "WGAN-GP Epoch 21/50, C_loss: 2.2185, G_loss: -2.9527\n",
      "WGAN-GP Epoch 22/50, C_loss: 1.8933, G_loss: -2.7238\n",
      "WGAN-GP Epoch 23/50, C_loss: 2.0064, G_loss: -2.8049\n",
      "WGAN-GP Epoch 24/50, C_loss: 1.9842, G_loss: -2.7981\n",
      "WGAN-GP Epoch 25/50, C_loss: 2.1776, G_loss: -2.4612\n",
      "WGAN-GP Epoch 26/50, C_loss: 1.7179, G_loss: -2.4963\n",
      "WGAN-GP Epoch 27/50, C_loss: 1.8048, G_loss: -2.5104\n",
      "WGAN-GP Epoch 28/50, C_loss: 1.9253, G_loss: -2.5227\n",
      "WGAN-GP Epoch 29/50, C_loss: 1.7306, G_loss: -2.4144\n",
      "WGAN-GP Epoch 30/50, C_loss: 1.8602, G_loss: -2.4708\n",
      "WGAN-GP Epoch 31/50, C_loss: 1.5724, G_loss: -2.3955\n",
      "WGAN-GP Epoch 32/50, C_loss: 1.5770, G_loss: -2.3293\n",
      "WGAN-GP Epoch 33/50, C_loss: 1.6485, G_loss: -2.5715\n",
      "WGAN-GP Epoch 34/50, C_loss: 1.8282, G_loss: -2.7118\n",
      "WGAN-GP Epoch 35/50, C_loss: 1.8343, G_loss: -2.7859\n",
      "WGAN-GP Epoch 36/50, C_loss: 1.8093, G_loss: -2.9357\n",
      "WGAN-GP Epoch 37/50, C_loss: 1.7117, G_loss: -2.8750\n",
      "WGAN-GP Epoch 38/50, C_loss: 1.6581, G_loss: -2.8901\n",
      "WGAN-GP Epoch 39/50, C_loss: 1.5454, G_loss: -3.0440\n",
      "WGAN-GP Epoch 40/50, C_loss: 1.5856, G_loss: -2.8381\n",
      "WGAN-GP Epoch 41/50, C_loss: 1.7944, G_loss: -3.0690\n",
      "WGAN-GP Epoch 42/50, C_loss: 1.5397, G_loss: -3.1555\n",
      "WGAN-GP Epoch 43/50, C_loss: 1.3393, G_loss: -3.0353\n",
      "WGAN-GP Epoch 44/50, C_loss: 1.5080, G_loss: -2.9895\n",
      "WGAN-GP Epoch 45/50, C_loss: 0.9404, G_loss: -2.9636\n",
      "WGAN-GP Epoch 46/50, C_loss: 0.7028, G_loss: -2.9521\n",
      "WGAN-GP Epoch 47/50, C_loss: 0.8410, G_loss: -2.8758\n",
      "WGAN-GP Epoch 48/50, C_loss: 0.2814, G_loss: -2.8000\n",
      "WGAN-GP Epoch 49/50, C_loss: 0.5256, G_loss: -2.6935\n",
      "WGAN-GP Epoch 50/50, C_loss: -0.2151, G_loss: -2.7502\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 800ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 813ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 799ms/step\n",
      "WGAN-GP Evaluation - IS: 1.0001, FID: 333.2527\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
